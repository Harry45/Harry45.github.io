<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Arrykrishna Mootoovaloo</title>
    <description>501, Lower Main Road, Millskock House, Observatory, Cape Town, 7935</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Sun, 21 May 2017 10:41:18 +0400</pubDate>
    <lastBuildDate>Sun, 21 May 2017 10:41:18 +0400</lastBuildDate>
    <generator>Jekyll v3.3.0</generator>
    
      <item>
        <title>Bayesian School 2016</title>
        <description>&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
  MathJax.Hub.Config({ TeX: { extensions: [&quot;color.js&quot;] }});
&lt;/script&gt;

&lt;p align=&quot;justify&quot;&gt;The 2016 Bayesian School was organised at the University of Stellenbosch from the 21&lt;sup&gt;st&lt;/sup&gt; to 25&lt;sup&gt;th&lt;/sup&gt; November. In particular, the school focused on three main topics namely, Introductory Bayesian Methods, Monte Carlo Methods and Advanced Bayesian Methods which was taught by &lt;a href=&quot;http://astro.ic.ac.uk/aheavens/home&quot;&gt;Prof. Alan Heavens&lt;/a&gt; from Imperial College. &lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Apart from the lectures, another interesting part of the school was &quot;Research Hacks&quot;. The latter allows participants to meet in small groups, ask questions, exchange ideas and initiate collaboration. While these hacks predominantly followed the said-intentions, this also led to the publication of three papers (see &lt;a href=&quot;https://arxiv.org/abs/1704.03472&quot;&gt;arXiv:1704.03472&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/abs/1704.03467&quot;&gt;arXiv:1704.03467&lt;/a&gt; and &lt;a href=&quot;https://arxiv.org/abs/1704.07830&quot;&gt;arXiv:1704.07830&lt;/a&gt;). &lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;I learned quite a lot from Prof. Alan lectures and have also attempted some of the questions he proposed during the school. In particular, I will discuss two topics, namely KL Divergence and Bayesian Hierarchical Modelling below.&lt;/p&gt;

&lt;h2&gt;Kullback-Leibler (KL) Divergence&lt;/h2&gt;
&lt;p align=&quot;justify&quot;&gt;Suppose, we have a prior distribution which we denote as $\pi\left(\boldsymbol{\theta}\right)$ on the set of parameters $\boldsymbol{\theta}$. Afterwards, this is updated via Bayes' Theorem to a posterior distribution which we call $q\left(\boldsymbol{\theta}\right)$ and we want to know how much information we have gained from this update. This information can be quantified using the Kullback-Leibler (KL) Divergence,

\begin{align}
\textrm{D}_{\textrm{KL}}\left(q\left\Vert \pi\right.\right)=\int q\,\textrm{log}\left(\dfrac{q}{\pi}\right)d\theta
\end{align}

It is also referred to as the &lt;i&gt;relative entropy&lt;/i&gt;. If this quantity is measured in base of logarithm of 2, the information gain is in &lt;i&gt;bits&lt;/i&gt;, otherwise if measured in base of logarithm of $e$, the information gain is in &lt;i&gt;nats&lt;/i&gt;. To illustrate the KL Divergence, let us consider a simple example, the KL Divergence of two Gaussians. Consider the prior and posterior distributions with means $\mu_{1},\,\mu_{2}$ and variances $\sigma_{1}^{2},\,\sigma_{2}^{2}$. The KL Divergence of $q$ from $\pi$ is

$$
\textrm{D}\left(q\left\Vert \pi\right.\right)=\dfrac{\left(\mu_{1}-\mu_{2}\right)^{2}}{2\sigma_{1}^{2}}+\dfrac{\sigma_{2}^{2}}{2\sigma_{1}^{2}}-\dfrac{1}{2}-\textrm{log}\left(\dfrac{\sigma_{2}}{\sigma_{1}}\right)
$$

From the above result, if the variance of the posterior distribution, that is, $\sigma_{2}^{2}$ decreases, then the information content increases, while if there is a huge difference between the two means, the information gain may increase significantly.&lt;/p&gt;

&lt;div style=&quot;background-color: #FFF8C6; margin-left: 20px; margin-right: 20px; padding-bottom: 8px; padding-left: 8px; padding-right: 8px; padding-top: 8px;&quot;&gt;

&lt;p align=&quot;justify&quot;&gt;Another question related to KL Divergence was,&lt;/p&gt;&lt;br /&gt;

&lt;p align=&quot;justify&quot; style=&quot;margin-left: 40px; margin-right: 40px&quot;&gt;&lt;i&gt;We have an experiment where a single datum $x$ is assumed to be drawn from a Gaussian Likelihood of mean $\mu$ and variance $\sigma^{2}$. Compute the KL divergence between an assumed Gaussian prior on $\mu$ (with mean zero and variance $\Sigma$) and the posterior.&lt;/i&gt;&lt;/p&gt;&lt;br /&gt;

For this question, the KL Divergence is given by

$$
\textrm{D}_{\textrm{KL}}\left(q\left\Vert \pi\right.\right)=-\dfrac{1}{2}+\dfrac{\sigma^{2}}{2\left(\Sigma+\sigma^{2}\right)}+\dfrac{x^{2}\Sigma}{2\left(\Sigma+\sigma^{2}\right)^{2}}-\dfrac{1}{2}\textrm{log}\left(\dfrac{\sigma^{2}}{\Sigma+\sigma^{2}}\right)
$$

&lt;p align=&quot;justify&quot;&gt;If we had naively assumed a Dirac-Delta prior on the parameter, that is, $\Sigma=0$, then, $\textrm{D}_{\textrm{KL}}\left(q\left\Vert \pi\right.\right)=0$, which means there is no information gain. From my viewpoint, this example of computing the KL Divergence indicates the essence of incorporating priors in our analysis, which in turn leads us to advocating the Bayesian formalism.&lt;/p&gt;

 
&lt;/div&gt;

&lt;h2&gt;Bayesian Hierarchical Modelling&lt;/h2&gt;

&lt;p align=&quot;justify&quot;&gt;This is also one of the topics which helped me to answer one of my questions: how do we proceed with parameter inference when we have error bars on both dependent and independent variables? The idea behind Bayesian Hierarchical Modelling (BHM) is to split the problem into steps where the full model now consists of a series of sub-models.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;BHM links each sub-models, thereby propagating uncertainties from one sub-model to another. Let us consider a simple example, where we are fitting a straight line, $y=mx$ to a single data point, $X$ and $Y$. The complication is that both $X$ and $Y$ have errors, $\sigma_{X}$ and $\sigma_{Y}$ respectively. The question is: how do we infer $m$? In other words, we want $\mathcal{P}\left(m\left|X,\,Y\right.\right)$.&lt;/p&gt;

&lt;div style=&quot;background-color: #FFF8C6; margin-left: 20px; margin-right: 20px; padding-bottom: 8px; padding-left: 8px; padding-right: 8px; padding-top: 8px;&quot;&gt;

&lt;p align=&quot;justify&quot;&gt;In this part, we will go through the steps in the BHM. To start with, we first need to write Bayes' Theorem, that is,&lt;/p&gt;

$$
\mathcal{P}\left(m\left|X,\,Y\right.\right)=\dfrac{\mathcal{P}\left(X,\,Y\left|m\right.\right)\mathcal{P}\left(m\right)}{\mathcal{P}\left(X,\,Y\right)}\propto\mathcal{P}\left(X,\,Y\left|m\right.\right)\mathcal{P}\left(m\right)
$$

&lt;p align=&quot;justify&quot;&gt;We then introduce the so-called latent variables, $x$ and $y$ and since we are not interested in them, we will marginalise over them as follows,&lt;/p&gt;


$$
\mathcal{P}\left(m\left|X,\,Y\right.\right)\propto \int {\color{red}\mathcal{P}\left(X,\,Y,\,x,\,y\left|m\right.\right)}\mathcal{P}\left(m\right)dxdy
$$
 
&lt;p align=&quot;justify&quot;&gt;Using the product rule, we have&lt;/p&gt;


$$
\mathcal{P}\left(m\left|X,\,Y\right.\right)\propto\int{\color{red}\mathcal{P}\left(X,\,Y\left|x,\,y,\,m\right.\right){\color{blue}\mathcal{P}\left(x,\,y\left|m\right.\right)}}\mathcal{P}\left(m\right)dxdy
$$
 
&lt;p align=&quot;justify&quot;&gt;In this case, the first probability does not depend on $m$, that is, $\mathcal{P}\left(X,\,Y\left|x,\,y,\,m\right.\right) = \mathcal{P}\left(X,\,Y\left|x,\,y\right.\right)$ and using the product rule again, we have&lt;/p&gt;

$$
\mathcal{P}\left(m\left|X,\,Y\right.\right)\propto\int{\color{red}\mathcal{P}\left(X,\,Y\left|x,\,y\right.\right){\color{blue}{\color{magenta}\mathcal{P}\left(y\left|m,\,x\right.\right)}\mathcal{P}\left(x\left|m\right.\right)}}\mathcal{P}\left(m\right)dxdy
$$
 
&lt;p align=&quot;justify&quot;&gt;Our model is deterministic, that is, $\mathcal{P}\left(y\left|m,\,x\right.\right) = \delta\left(y-mx\right)$. Therefore,&lt;/p&gt;


$$
\mathcal{P}\left(m\left|X,\,Y\right.\right)\propto\int{\color{red}\mathcal{P}\left(X,\,Y\left|x,\,mx\right.\right){\color{magenta}\delta\left(y-mx\right)}{\color{blue}\mathcal{P}\left(x\right)}}\mathcal{P}\left(m\right)dxdy
$$

&lt;p align=&quot;justify&quot;&gt;Assuming uniform priors on $\mathcal{P}\left(x\right)$ and $\mathcal{P}\left(m\right)$, we have, &lt;/p&gt;

$$
\mathcal{P}\left(m\left|X,\,Y\right.\right)\propto\int{\color{red}\mathcal{P}\left(X,\,Y\left|x,\,mx\right.\right)}\,dx
$$

&lt;p align=&quot;justify&quot;&gt;We further assume that we know the sampling distribution of $X$ and $Y$ and that they are indendent such that&lt;/p&gt;

$$
\mathcal{P}\left(X,\,Y\left|x,\,y\right.\right)=\mathcal{P}\left(X\left|x\right.\right)\mathcal{P}\left(Y\left|y\right.\right)
$$
 
&lt;p align=&quot;justify&quot;&gt;We further assume that the errors in $X$ and $Y$ are independent Gaussians and for simplicity we take $\sigma_{X}=\sigma_{Y}=1$. Therefore,&lt;/p&gt;

$$
\mathcal{P}\left(m\left|X,\,Y\right.\right)\propto\int e^{-\frac{1}{2}\left(X-x\right)^{2}}e^{-\frac{1}{2}\left(Y-mx\right)^{2}}dx
$$


&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;After completing the square and performing the above integration, the unnormalised posterior distribution of $m$ is given by, &lt;/p&gt;

&lt;p&gt;\begin{equation}
\mathcal{P}\left(m\left|X,\,Y\right.\right)\propto\dfrac{1}{\sqrt{1+m^{2}}}e^{-\frac{1}{2}\left(\frac{Y-mX}{\sqrt{1+m^{2}}}\right)^{2}}
\label{eq:post_m}
\end{equation}&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;One can also consider the joint posterior distribution of $x$ and $m$, which is simply given by Bayes' Theorem,&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{P}\left(x,\,m\left|X,\,Y\right.\right)\propto\mathcal{P}\left(X,\,Y\left|x,\,mx\right.\right)\mathcal{P}\left(x\right)\mathcal{P}\left(m\right)&lt;/script&gt;

&lt;p&gt;\begin{equation}
\mathcal{P}\left(x,\,m\left|X,\,Y\right.\right)\propto e^{-\frac{1}{2}\left(X-x\right)^{2}}e^{-\frac{1}{2}\left(Y-mx\right)^{2}}
\end{equation}&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Consider the case where $X=10$ and $Y=15$. Using Equation \eqref{eq:post_m}, the posterior distribution of $m$ is shown in the left panel of the figure below. In addition, using Gibbs Sampling, the joint posterior distribution of $x$ and $m$ is shown in the right panel of the figure below. &lt;/p&gt;

&lt;dl class=&quot;wp-caption aligncenter&quot; style=&quot;max-width: 800px&quot;&gt;

&lt;dt&gt;&lt;a href=&quot;&quot;&gt;&lt;img class=&quot;&quot; src=&quot;/images/posterior_m.jpg&quot; alt=&quot;The left panel shows the posterior distribution of $m$ while the right panel shows the joint posterior distribution of $x$ and $m$ using Gibbs Sampling.&quot; /&gt;&lt;/a&gt;&lt;/dt&gt;

&lt;dd&gt;The left panel shows the posterior distribution of $m$ while the right panel shows the joint posterior distribution of $x$ and $m$ using Gibbs Sampling.&lt;/dd&gt;
&lt;/dl&gt;

</description>
        <pubDate>Thu, 02 Mar 2017 12:00:00 +0400</pubDate>
        <link>http://localhost:4000/blog/2017/03/Bayesian-School-2016</link>
        <guid isPermaLink="true">http://localhost:4000/blog/2017/03/Bayesian-School-2016</guid>
        
        
        <category>Workshop and Conference</category>
        
      </item>
    
      <item>
        <title>Bayesian Model Selection</title>
        <description>&lt;script type=&quot;text/x-mathjax-config&quot;&gt;
  MathJax.Hub.Config({ TeX: { extensions: [&quot;color.js&quot;] }});
&lt;/script&gt;

&lt;p align=&quot;justify&quot;&gt;Given a data set, one could presumably use various models to explain the data. One of the key questions underlying science is that of model selection: how do we select between competing theories which purport to explain observed data? The great paradigm shifts in science fall squarely into this domain. With so many models available to us, overfitting remains a real issue. Hence, choosing the most suitable model is essential in the Statistics world.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;In the context of astronomy - as with most areas of science - the next two decades will see a massive increase in data volume through large surveys such as the Square Kilometre Array (SKA) and the Large Synoptic Survey Telescope (LSST). Robust statistical analysis to perform model selection at scale will be a critical factor in the success of such future surveys.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Although, we might have very good data, we may not know when to stop fitting. Two competing models may equally fit the data properly but how do we choose the most appropriate model? The solution in fact lies in the simpler model being preferred. This is known as the &lt;i&gt;Occam’s razor&lt;/i&gt;. The complex model which explains the data somewhat better compared to the simpler model should be penalised for the additional parameters that it introduces. Extra parameters bring about lack of predictability. In this spectrum, Bayesian model selection is becoming an increasingly important tool to determine whether or not the introduction of a new parameter is justified by the data.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;In this post, we will focus only on the calculation of the &lt;b&gt;Bayesian Evidence&lt;/b&gt;, which is often regarded as the average likelihood under the prior. The evidence is the normalisation integral of the product of the likelihood and the prior and is often referred to as the &lt;i&gt;model likelihood&lt;/i&gt;, or the &lt;i&gt;marginal likelihood&lt;/i&gt; and is denoted by $\mathbb{Z}$. It is interpreted as the probability of the data $\left(\mathcal{D}\right)$ given the model $\left(\mathcal{M}\right)$. The Bayesian Evidence is given as &lt;/p&gt;

&lt;p&gt;\begin{equation}
\mathbb{Z}\equiv\mathcal{P}\left(\mathcal{D}\left|\mathcal{M}\right.\right)=\int\mathcal{P}\left(\mathcal{D}\left|\boldsymbol{\theta},\,\mathcal{M}\right.\right)\,\mathcal{P}\left(\boldsymbol{\theta}\left|\mathcal{M}\right.\right)\,d\boldsymbol{\theta}
\end{equation}&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;where $\mathcal{P}\left(\mathcal{D}\left|\boldsymbol{\theta},\,\mathcal{M}\right.\right)$ is the likelihood function which should typically reflect the way the data is obtained and $\mathcal{P}\left(\boldsymbol{\theta}\left|\mathcal{M}\right.\right)$ is the prior distribution for the parameters. Using Bayes' theorem, we can write&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{P}\left(\mathcal{M}\left|\mathcal{D}\right.\right)=\dfrac{\mathcal{P}\left(\mathcal{D}\left|\mathcal{M}\right.\right)\mathcal{P}\left(\mathcal{M}\right)}{\mathcal{P}\left(\mathcal{D}\right)}&lt;/script&gt;

&lt;p align=&quot;justify&quot;&gt;The left-hand side of equation is the posterior probability of the model given the data. Consider two competing models $\mathcal{M}_{1}$ and $\mathcal{M}_{2}$. The ratio of the respective posterior probabilities of the models, given the data is&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\dfrac{\mathcal{P}\left(\mathcal{M}_{1}\left|\mathcal{D}\right.\right)}{\mathcal{P}\left(\mathcal{M}_{2}\left|\mathcal{D}\right.\right)}=\dfrac{\mathcal{P}\left(\mathcal{D}\left|\mathcal{M}_{1}\right.\right)}{\mathcal{P}\left(\mathcal{D}\left|\mathcal{M}_{2}\right.\right)}\,\dfrac{\mathcal{P}\left(\mathcal{M}_{1}\right)}{\mathcal{P}\left(\mathcal{M}_{2}\right)}&lt;/script&gt;

&lt;p align=&quot;justify&quot;&gt;Note that $\mathcal{P}\left(\mathcal{D}\right)$ is only a constant and can be dropped when calculating the ratio of posterior probability of the models. The ratio $$B_{12}=\dfrac{\mathcal{P}\left(\mathcal{D}\left|\mathcal{M}_{1}\right.\right)}{\mathcal{P}\left(\mathcal{D}\left|\mathcal{M}_{2}\right.\right)}$$ is the &lt;b&gt;Bayes factor&lt;/b&gt; and is, in fact, the ratio of the models' evidences. The ratio $$\dfrac{\mathcal{P}\left(\mathcal{M}_{1}\left|\mathcal{D}\right.\right)}{\mathcal{P}\left(\mathcal{M}_{2}\left|\mathcal{D}\right.\right)}$$ is the posterior odds while $$\dfrac{\mathcal{P}\left(\mathcal{M}_{1}\right)}{\mathcal{P}\left(\mathcal{M}_{2}\right)}$$ is the prior odds. Therefore, in words, one can describe the above as &lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\textrm{posterior odds}=\textrm{Bayes Factor}\times\textrm{prior odds}&lt;/script&gt;

&lt;p align=&quot;justify&quot;&gt;In the case of non-committal priors on the models, that is, $\mathcal{P}\left(\mathcal{M}_{1}\right)=\mathcal{P}\left(\mathcal{M}_{2}\right)$, the posterior odds are just equal to the Bayes factor. As $B_{12}$ increases, our belief that model $\mathcal{M}_{1}$ is better than model $\mathcal{M}_{2}$ increases. Otherwise, model $\mathcal{M}_{2}$ will be the preferred one. Therefore, the Bayes factor indicates how the relative odds vary in the light of new data, irrespective of the prior odds of the models. The Bayes factor is typically interpreted by referring to the Jeffreys' scale (see &lt;a href=&quot;http://www.tandfonline.com/doi/abs/10.1080/01621459.1995.10476572&quot;&gt;Kass et al., 1995&lt;/a&gt;). It is an empirically determined scale as shown in the table below &lt;/p&gt;

&lt;style&gt;
table, td, th {
    border: 1px solid black;
}

table {
    border-collapse: collapse;
    width: 53%;
}

&lt;/style&gt;

&lt;style type=&quot;text/css&quot;&gt;
	table.tableizer-table {
		font-size: 14px;
		border: 2px solid #CCC; 
		font-family: Arial, Helvetica, sans-serif;
	} 
	.tableizer-table td {
		padding: 6px;
		margin: 3px;
		border: 1px solid #CCC;
	}
	.tableizer-table th {
		background-color: #104E8B;
		padding: 6px; 
		color: #FFF;
		font-weight: bold;
	}
&lt;/style&gt;

&lt;table class=&quot;tableizer-table&quot; align=&quot;center&quot;&gt;
&lt;thead&gt;&lt;tr class=&quot;tableizer-firstrow&quot;&gt;&lt;th&gt;$\textrm{ln }\left(B_{12}\right)$&lt;/th&gt;&lt;th&gt;$B_{12}$&lt;/th&gt;&lt;th&gt;Evidence against $\mathcal{M}_{2}$&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;
 &lt;tr&gt;&lt;td align=&quot;center&quot;&gt;0 to 1&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;1 to 3&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;Inconclusive&lt;/td&gt;&lt;/tr&gt;
 &lt;tr&gt;&lt;td align=&quot;center&quot;&gt;1 to 3&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;3 to 20&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;Weak Evidence&lt;/td&gt;&lt;/tr&gt;
 &lt;tr&gt;&lt;td align=&quot;center&quot;&gt;3 to 5&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;20 to 150&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;Moderate Evidence&lt;/td&gt;&lt;/tr&gt;
 &lt;tr&gt;&lt;td align=&quot;center&quot;&gt;&amp;gt;5&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;&amp;gt;150&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;Strong Evidence&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

</description>
        <pubDate>Thu, 02 Mar 2017 10:00:00 +0400</pubDate>
        <link>http://localhost:4000/blog/2017/03/Bayesian-Model-Selection</link>
        <guid isPermaLink="true">http://localhost:4000/blog/2017/03/Bayesian-Model-Selection</guid>
        
        
        <category>Machine Learning and Statistics</category>
        
      </item>
    
      <item>
        <title>Linear Regression</title>
        <description>&lt;p align=&quot;justify&quot;&gt;One common problem in Statistics is to learn a functional relationship between independent variables and dependent variable. For example, we may want to know how the price of houses varies with the area of the land, the total size of the house and various other criteria. In this particular case, the price of the houses is the dependent variable, also often referred to as the response variable while the area of the land and total size of the house are the independent variables, also known as the attribute variables.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;We will first begin with linear modelling, that is, given a set of attributes, we want infer a linear relationship between the attributes and the response. The function which we want to fit is typically governed by a set of parameters, say $\theta_{i}$. However, before indulging into this topic, it is worth discussing linear and non-linear models.&lt;/p&gt;

&lt;div style=&quot;background-color: #FFF8C6; margin-left: 20px; margin-right: 20px; padding-bottom: 8px; padding-left: 8px; padding-right: 8px; padding-top: 8px;&quot;&gt;
&lt;b&gt;Linear and Non-Linear Models&lt;/b&gt;&lt;br /&gt;
The equation

\begin{align}
y=\theta_{0} + \theta_{1}x + \theta_{2}x^2
\end{align}

is a linear model model because it is linear in the parameters $\theta_{i}$. In contrast, the model 

\begin{align}
y=\textrm{sin}\left(\omega x + \phi\right)
\end{align}

is a non-linear model since it includes parameters $\left(\omega,\,\phi\right)$ which are non-linear. 
 
&lt;/div&gt;

&lt;h2&gt;Maximum Likelihood Method&lt;/h2&gt;
&lt;p align=&quot;justify&quot;&gt;Suppose, we now want to fit a polynomial $f\left(x\right)$ of order $M$ to some observed data $\left(x_{i},\,y_{i}\right)$ where $i=0,\,1,\,2,\ldots N-1$. We further assume that they are corrupted with Gaussian noise, $\sigma_{i}$. Then, each observed datum can be described by a Gaussian:

\begin{align}
\mathcal{P}\left(y_{i}\left|\boldsymbol{\theta}\right.\right)=\dfrac{1}{\sqrt{2\pi\sigma_{i}^{2}}}\,\textrm{exp}\left[-\dfrac{1}{2}\left(\dfrac{y_{i}-f\left(x_{i}\left|\boldsymbol{\theta}\right.\right)}{\sigma_{i}}\right)^{2}\right]
\end{align}

where $\boldsymbol{\theta}$ is the set of parameters $\left(\theta_{0},\,\theta_{1},\ldots \theta_{M}\right)$. For simplicity, we will explain this method by using a linear fit to the data, that is, $f\left(x\left|\theta_{0},\,\theta_{1}\right.\right)=\theta_{0}+\theta_{1}x$. Assuming that the data point is independent from each other, the likelihood is simply a product of the individual probability distribution of the above. 

&lt;/p&gt;

&lt;div style=&quot;background-color: #FFF8C6; margin-left: 20px; margin-right: 20px; padding-bottom: 8px; padding-left: 8px; padding-right: 8px; padding-top: 8px;&quot;&gt;
&lt;b&gt;Matrix and Vector Notations&lt;/b&gt;&lt;br /&gt;
We will define the vector $\mathbf{b}$ as:

$$
\mathbf{b=\left(\begin{array}{c}
\frac{y_{0}}{\sigma_{0}}\\
\\
\vdots\\
\\
\frac{y_{N-1}}{\sigma_{N-1}}
\end{array}\right)}
$$

and the design matrix, $\mathbf{D}$ as: 

$$
\mathbf{D}=\left(\begin{array}{cc}
\frac{1}{\sigma_{0}} &amp;amp; \frac{x_{0}}{\sigma_{0}}\\
\\
\\
\\
\frac{1}{\sigma_{N-1}} &amp;amp; \frac{x_{N-1}}{\sigma_{N-1}}
\end{array}\right)
 
$$
&lt;/div&gt;

&lt;p align=&quot;justify&quot;&gt;Therefore, the likelihood (ignoring the pre-factor) can be written as:

\begin{align}
\mathcal{P}\left(\mathbf{y}\left|\boldsymbol{\theta}\right.\right)\propto\textrm{exp}\left[-\dfrac{1}{2}\left(\mathbf{b-\mathbf{D}\boldsymbol{\theta}}\right)^{\textrm{T}}\left(\mathbf{b-\mathbf{D}\boldsymbol{\theta}}\right)\right]
\label{eq:likelihood}
\end{align}

Our aim is to maximise the likelihood. Therefore, the derivative of the likelihood with respect to the parameters should be equal to zero. However, maximising the likelihood is equivalent to maximising the log-likelihood since the latter is a monotonic transformation applied to the likelihood. Some useful tricks when differentiating with respect to a vector are given below.&lt;/p&gt;

&lt;div style=&quot;background-color: #FFF8C6; margin-left: 20px; margin-right: 20px; padding-bottom: 8px; padding-left: 8px; padding-right: 8px; padding-top: 8px;&quot;&gt;
&lt;b&gt;Differentiating with respect to a vector&lt;/b&gt;&lt;br /&gt;

$$
\dfrac{\partial\mathbf{A}\mathbf{x}}{\partial\mathbf{x}}=\mathbf{A}
$$

$$
\dfrac{\partial\mathbf{x}^{\textrm{T}}\mathbf{A}}{\partial\mathbf{x}}=\mathbf{A}^{\textrm{T}}
$$

If $\mathbf{A}$ is a symmetric matrix, 
$$
\dfrac{\partial\mathbf{x}^{\textrm{T}}\mathbf{A}\mathbf{x}}{\partial\mathbf{x}}=2\mathbf{x}^{\textrm{T}}\mathbf{A}
$$

For further details, see &lt;a href=&quot;https://en.wikipedia.org/wiki/Matrix_calculus&quot;&gt;Wikipedia&lt;/a&gt; or the &lt;a href=&quot;http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/3274/pdf/imm3274.pdf&quot;&gt;Matrix Cookbook.&lt;/a&gt;
&lt;/div&gt;

&lt;p align=&quot;justify&quot;&gt;Using Equation \eqref{eq:likelihood} and the above useful identities, &lt;/p&gt;

&lt;p&gt;\begin{align}
\boldsymbol{\theta}_{\textrm{MLE}}=\left(\mathbf{D}^{\textrm{T}}\mathbf{D}\right)^{-1}\mathbf{D}^{\textrm{T}}\mathbf{b}
\end{align}&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt; The matrix $\mathbf{C}=\left(\mathbf{D}^{\textrm{T}}\mathbf{D}\right)^{-1}$ is called the covariance matrix and gives the standard uncertainties associated with the parameters determined. In particular, the diagonal elements of this matrix give the variances of the parameters while the off-diagonal elements give the covariances between the parameters $\theta_{j}$ and $\theta_{k}$. Hence, the errors on the parameters are equal to the square root of the diagonal elements of the covariance matrix $\mathbf{C}$.&lt;/p&gt;

&lt;h2&gt;Example - A Physics Problem&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;/images/Linear_Regression_Circuit.png&quot; align=&quot;left&quot; width=&quot;420&quot; /&gt;&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;We will use the above explanation to answer a Physics problem (Physics 9702 November 2016 Paper 52). A student is investigating the characteristics of different light-emitting diodes (LEDs). Each LED
needs a minimum potential difference across it to emit light. The circuit is set up as shown on the left. &lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;The potentiometer is adjusted until the LED just emits light. The potential difference $V$ across the LED is measured. The experiment is repeated for LEDs that emit light of different wavelength $\lambda$. It is suggested that $V$ and $\lambda$ are related by the equation

\begin{align}
V=p\lambda^{q}
\end{align}

where $p$ and $q$ are constants. Therefore, if we are to plot a graph of $\textrm{lg }V$ on the $y$-axis against $\textrm{lg }\lambda$ on the $x$-axis, the gradient of the straight line will correspond to $q$ while the $y$-intercept to $\textrm{lg }p$. To be explicit, 

$$
\textrm{lg }V = q\,\textrm{lg }\lambda + \textrm{lg }p
$$
&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Linear_Regression_Data.png&quot; align=&quot;right&quot; width=&quot;420&quot; /&gt;&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;The values of $V$ and $\lambda$ are given in the table below and we also calculate $\textrm{lg }\lambda$ and $\textrm{lg }V$, with its associated error. The error in $\textrm{lg }V$ is:

$$
\sigma_{\textrm{lg }V} = \dfrac{\Delta V}{V}
$$

See this &lt;a href=&quot;http://phys114115lab.capuphysics.ca/App%20A%20-%20uncertainties/appA%20propLogs.htm&quot;&gt;link&lt;/a&gt; for further detail. For this problem, we calculate $\textrm{lg }\lambda$ and $\textrm{lg }V$ to two decimal places. We assume that each data point is Gaussian distributed with mean, $\mu=\textrm{lg }V$ and standard deviation, $\sigma = \sigma_{\textrm{lg }V}$. An illustration of this assumption is shown on the right. We are now ready to plot the graph of $\textrm{lg }V$ versus $\textrm{lg }\lambda$. We find that the gradient is equal to $2.60$ while the $y$-intercept is equal to $7.56$.&lt;/p&gt;

&lt;style&gt;
table, td, th {
    border: 1px solid black;
}

table {
    border-collapse: collapse;
    width: 53%;
}

&lt;/style&gt;

&lt;style type=&quot;text/css&quot;&gt;
	table.tableizer-table {
		font-size: 13px;
		border: 1px solid #CCC; 
		font-family: Arial, Helvetica, sans-serif;
	} 
	.tableizer-table td {
		padding: 6px;
		margin: 3px;
		border: 1px solid #CCC;
	}
	.tableizer-table th {
		background-color: #104E8B;
		padding: 6px; 
		color: #FFF;
		font-weight: bold;
	}
&lt;/style&gt;

&lt;table class=&quot;tableizer-table&quot; align=&quot;left&quot;&gt;
&lt;thead&gt;&lt;tr class=&quot;tableizer-firstrow&quot;&gt;&lt;th&gt;$\lambda/10^{-9}$ m &lt;/th&gt;&lt;th&gt;$V/\,\textrm{V}$&lt;/th&gt;&lt;th&gt;$\textrm{lg}\left(\lambda/10^{-9}\,\textrm{m}\right)$&lt;/th&gt;&lt;th&gt;$\textrm{lg}\left(V/\,\textrm{V}\right)$&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;
 &lt;tr&gt;&lt;td align=&quot;center&quot;&gt;630&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;$1.9\pm0.1$&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;2.80&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;$ 0.28\pm0.05$ &lt;/td&gt;&lt;/tr&gt;
 &lt;tr&gt;&lt;td align=&quot;center&quot;&gt;620&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;$2.0\pm0.1$&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;2.79&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;$0.30\pm0.05$ &lt;/td&gt;&lt;/tr&gt;
 &lt;tr&gt;&lt;td align=&quot;center&quot;&gt;590&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;$2.3\pm0.1$&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;2.77&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;$0.36\pm0.04$&lt;/td&gt;&lt;/tr&gt;
 &lt;tr&gt;&lt;td align=&quot;center&quot;&gt;520&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;$3.1\pm0.1$&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;2.72&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;$0.49\pm0.03$&lt;/td&gt;&lt;/tr&gt;
 &lt;tr&gt;&lt;td align=&quot;center&quot;&gt;490&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;$3.7\pm0.1$&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;2.69&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;$0.57\pm0.03$&lt;/td&gt;&lt;/tr&gt;
 &lt;tr&gt;&lt;td align=&quot;center&quot;&gt;470&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;$4.1\pm0.1$&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;2.67&lt;/td&gt;&lt;td align=&quot;center&quot;&gt;$0.61\pm0.02$&lt;/td&gt;&lt;/tr&gt;
&lt;/tbody&gt;&lt;/table&gt;

&lt;p align=&quot;justify&quot; style=&quot;margin-left:32em&quot;&gt;Moreover, the covariance matrix is: 

$$
\mathbf{C}=\left(\begin{array}{cc}
0.670 &amp;amp; -0.258\\
-0.258 &amp;amp; 0.095
\end{array}\right)
 
$$

Hence, 

$$
q=-2.60\pm0.84
$$

$$
\textrm{lg }p = 7.56\pm0.31
$$
&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/images/Linear_Regression_Fit.png&quot; align=&quot;right&quot; width=&quot;420&quot; /&gt;&lt;/p&gt;

&lt;p align=&quot;justify&quot; style=&quot;margin-top:3em&quot;&gt;Therefore, in short, the estimates of $p$ and $q$ are $3.61\times10^{7}$ and $-2.60$ respectively. We can also learn about the correlation between the two parameters from the covariance matrix. In particular, since the off-diagonal elements are negative, this implies that the two parameters are negatively correlated, that is, an increase in one parameter results in the decrease of the other. This is illustrated in the figure below, which also shows the credible intervals at $1\sigma$, $2\sigma$ and $3\sigma$. It is also worth mentioning that the distribution of the two parameters $\left(\textrm{lg }p,\,q\right)$ are Gaussian distributed since we are working with a linear model. In addition to this, we can use the values of $p$ and $q$ to estimate the minimum potential difference required if a different diode is used, for example, a diode emitting a wavelength of $950$ nm. 
&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/Linear_Regression_Correlation.png&quot; align=&quot;left&quot; width=&quot;420&quot; /&gt;&lt;/p&gt;

&lt;h2&gt;Summary and Conclusion&lt;/h2&gt;
&lt;p align=&quot;justify&quot; style=&quot;margin-left:28em&quot;&gt;In this post, we have gone through one method of inferring parameters, namely, the Maximum Likelihood Estimator. We have also provided an example to illustrate this method. It does provide a good estimate of the parameters along with their associated errors. Moreover, we can also learn about the correlation between the parameters using the covariance matrix. &lt;/p&gt;

&lt;p align=&quot;justify&quot; style=&quot;margin-left:28em&quot;&gt;In addition to this, if we had some prior information on the parameters, then the concept of Bayesian Statistics is invoked. The concept is not very different, except that we would have had a prior probability distribution for each parameter. Additionally, instead of finding the MLE, we will end up having the MAP, that is, the Maximum a Posteriori estimates of the parameters. If uniform distributions are assumed, then the MAP coincide with the MLE.&lt;/p&gt;

</description>
        <pubDate>Thu, 02 Mar 2017 10:00:00 +0400</pubDate>
        <link>http://localhost:4000/blog/2017/03/Linear-Regression</link>
        <guid isPermaLink="true">http://localhost:4000/blog/2017/03/Linear-Regression</guid>
        
        
        <category>Machine Learning and Statistics</category>
        
      </item>
    
      <item>
        <title>Sampling From Any Distribution</title>
        <description>&lt;p align=&quot;justify&quot;&gt;One of the recent topics which I had to study was how to sample from any distribution. While this seems to be a trivial question, Google did not help me much, although I did also try to post the problem on &lt;a href=&quot;http://stackoverflow.com/questions/40263486/drawing-random-samples-from-any-distribution&quot;&gt;stackoverflow&lt;/a&gt;! Here, we will show three methods which we can use to generate random numbers from a distribution. In particular, we will look at some in-built functions in &lt;code&gt;scipy&lt;/code&gt;, acceptance-rejection sampling and will consider interpolation method as well. The distribution which we will use is given by &lt;/p&gt;

&lt;p&gt;\begin{align}
\mathcal{P}\left(x\right) = \dfrac{k\,x^3}{e^{2x} - 0.1}
\end{align}&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;where $k$ is the normalisation constant. Note that we will use the following notations: $\mathcal{P}\left(\centerdot\right)$ is the probability distribution function (PDF) while $\Phi\left(\centerdot\right)$ is the cumulative distribution function (CDF). The generic shape of this distribution follows that of a black body spectrum. This distribution is used only to illustrate the idea of sampling and we do not provide any relevant explanation to the actual physics of black body radiation in this post.&lt;/p&gt;

&lt;h2&gt;Using Scipy&lt;/h2&gt;

&lt;p align=&quot;justify&quot;&gt;The class &lt;code&gt;rv_continuous&lt;/code&gt; in &lt;code&gt;scipy.stats&lt;/code&gt; is straightforward to use. We simply need to define either the PDF or CDF using &lt;code&gt;_pdf&lt;/code&gt; and &lt;code&gt;_cdf&lt;/code&gt; respectively as shown below. We first define the PDF, followed by a function to normalise it. Note also that the PDF that we define in the class should be normalised.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;10.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1E4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Define function to normalise the PDF&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;normalisation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;simps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Define the distribution using rv_continuous&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;blackbody&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rv_continuous&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_pdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;const&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;const&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p align=&quot;justify&quot;&gt;We are now ready to use our above written functions to find $\mathcal{P}\left(x\right)$, $\Phi\left(x\right)$ and generate samples from the underlying distribution. We first need to instantiate it with the lower and upper limits given by &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;b&lt;/code&gt; respectively. In principle, if not defined, it will be considered to be from $-\infty$ to $+\infty$.&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;blackbody_distribution&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blackbody&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;blackbody_distribution&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Find the normalisation constant first&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;norm_constant&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;normalisation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# create pdf, cdf, random samples&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;pdf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blackbody_distribution&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;norm_constant&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;cdf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blackbody_distribution&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;norm_constant&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;samples&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;blackbody_distribution&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rvs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;const&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;norm_constant&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1E4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;dl class=&quot;wp-caption aligncenter&quot; style=&quot;max-width: 700px&quot;&gt;

&lt;dt&gt;&lt;a href=&quot;&quot;&gt;&lt;img class=&quot;&quot; src=&quot;/images/scipy_continuous.jpg&quot; alt=&quot;Samples generated using &amp;lt;code&amp;gt;rv_continuous&amp;lt;/code&amp;gt; from &amp;lt;code&amp;gt;scipy.stats&amp;lt;/code&amp;gt;&quot; /&gt;&lt;/a&gt;&lt;/dt&gt;

&lt;dd&gt;Samples generated using &lt;code&gt;rv_continuous&lt;/code&gt; from &lt;code&gt;scipy.stats&lt;/code&gt;&lt;/dd&gt;
&lt;/dl&gt;

&lt;p align=&quot;justify&quot;&gt;The above plot shows the PDF, CDF and the samples generated from the distribution. In particular, we choose to draw 10 000 random samples. &lt;code&gt;rv_continuous&lt;/code&gt; becomes useful when one needs more than just the samples. Once we have defined it, we can simply find other properties such as its mean, standard deviation and several more (see the &lt;a href=&quot;https://docs.scipy.org/doc/scipy-0.16.0/reference/generated/scipy.stats.rv_continuous.html&quot;&gt;documentation&lt;/a&gt; for further details).&lt;/p&gt;

&lt;h2&gt;Acceptance-Rejection Sampling&lt;/h2&gt;

&lt;dl class=&quot;wp-caption alignright&quot; style=&quot;max-width: 265px&quot;&gt;

&lt;dt&gt;&lt;a href=&quot;&quot;&gt;&lt;img class=&quot;&quot; src=&quot;/images/circle_accept_reject.jpg&quot; alt=&quot;Estimating value of $\pi$ using Monte Carlo Method&quot; /&gt;&lt;/a&gt;&lt;/dt&gt;

&lt;dd&gt;Estimating value of $\pi$ using Monte Carlo Method&lt;/dd&gt;
&lt;/dl&gt;

&lt;p align=&quot;justify&quot;&gt;Imagine we have a square board of size $l$, on which there is a circle of radius $0.5l$ at the centre of the board, that is, at $\left(0.5l,0.5l\right)$ in a Cartesian coordinate system. We are throwing darts randomly on the board, say $N$ times. If $n$ is the number of times that the darts lie within the circle, the probability of throwing the darts successfully into the circle is simply $\frac{n}{N}$. This is also roughly equal to the ratio of the area of the circle to the area of the square board. One could use this idea to have a rough estimate of the value of $\pi$, that is,&lt;/p&gt;
&lt;p&gt;\begin{align}
\pi \approx 4 \times \frac{n}{N}
\end{align}&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;As $N$ becomes larger, one would have a more accurate estimate of the number $\pi$. This is the idea behind Monte Carlo sampling. Through this lens, an alternative way to sample from a normalised distribution is to use acceptance-rejection sampling scheme. It is also sometimes referred to as Lahiri's Sampling method. This method is advantageous in the sense that we do not need to know the CDF. However, one downfall is that samples may get rejected very often. Moreover, say we want $N$ random numbers, it is unlikely that we will get that number of samples relatively easily. In this post, we have not implemented this method. In short,&lt;/p&gt;

&lt;p align=&quot;justify&quot; style=&quot;padding: 0px 100px 0px 100px&quot;&gt; suppose $X$ is a scalar random variable taking values in the interval $\left[a, b\right]$ according to the continuous probability density function $f\left(x\right)$. Let $M$ be an upper bound for $f$ on $\left[a, b\right]$, $M$ assumed finite. Choose $x$ uniformly in $\left[a, b\right]$. Then choose $u$ uniformly in $\left[0, M\right]$. If $u\leq f\left(x\right)$, we select $x$. Otherwise we reject $x$ and start over.&lt;/p&gt;

&lt;h2&gt;Interpolation Method&lt;/h2&gt;
&lt;p align=&quot;justify&quot;&gt;What do we do if neither of the two methods work but we do have the PDF? The procedures we adopt here is as follows:&lt;/p&gt;

&lt;ol type=&quot;1&quot;&gt;
  &lt;li&gt;Find the CDF using &lt;code&gt;np.cumsum&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;Generate a random number from a uniform distribution, $\mathcal{U}\left[0,1\right]$ &lt;/li&gt;
  &lt;li&gt;Use &lt;code&gt;interp1d&lt;/code&gt; from &lt;code&gt;scipy.interpolate&lt;/code&gt; to estimate the random number.&lt;/li&gt;
&lt;/ol&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;c&quot;&gt;# Our Own pdf, cdf and samples&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;own_pdf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;norm_constant&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;own_cdf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cumsum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;own_pdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;own_cdf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;own_cdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Define a function to return N samples&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;genSamples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uniform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;func_interp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;interp1d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;own_cdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;samples&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;func_interp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;u&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;samples&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;own_samples&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;genSamples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1E4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;dl class=&quot;wp-caption aligncenter&quot; style=&quot;max-width: 700px&quot;&gt;

&lt;dt&gt;&lt;a href=&quot;&quot;&gt;&lt;img class=&quot;&quot; src=&quot;/images/own_cdf_pdf_samples.jpg&quot; alt=&quot;Samples generated using the CDF and interpolation method&quot; /&gt;&lt;/a&gt;&lt;/dt&gt;

&lt;dd&gt;Samples generated using the CDF and interpolation method&lt;/dd&gt;
&lt;/dl&gt;

&lt;p align=&quot;justify&quot;&gt;Here we have a nice distribution with 10 000 random samples drawn using the CDF. It looks similar to the one using &lt;code&gt;rv_continuous&lt;/code&gt;!&lt;/p&gt;
</description>
        <pubDate>Fri, 28 Oct 2016 12:26:00 +0400</pubDate>
        <link>http://localhost:4000/blog/2016/10/Sampling-From-Any-Distribution</link>
        <guid isPermaLink="true">http://localhost:4000/blog/2016/10/Sampling-From-Any-Distribution</guid>
        
        
        <category>Machine Learning and Statistics</category>
        
      </item>
    
      <item>
        <title>An Introduction to Gibbs Sampling</title>
        <description>&lt;p align=&quot;justify&quot;&gt;Gibbs sampling is a variant of Markov Chain Monte Carlo (MCMC) method (&lt;a href=&quot;https://en.wikipedia.org/wiki/Gibbs_sampling&quot;&gt;Wikipedia&lt;/a&gt;). The idea is to update one of the parameters at a time, thus requiring conditional distributions. As with the standard Metropolis-Hastings algorithm, samples generated from an accumulated Gibbs chain are correlated with nearby samples and hence, if independent samples are required, it is desired to thin the chain by taking every n&lt;sup&gt;th&lt;/sup&gt; value. Moreover, the initial samples (burn-in) are negelected as they may not actually represent the underlying &quot;true&quot; distribution. The algorithm for Gibbs sampling is as follows:
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;Initialise $\boldsymbol{\theta}=\left(\theta_{0},\,\theta_{1},\,\ldots\theta_{n}\right)$.&lt;/li&gt; 
&lt;li&gt;Sample for the parameters as below:&lt;/li&gt;
&lt;ul&gt;
&lt;li&gt;Sample $\theta_{0}'$ from $\theta_{0}\left|\theta_{0},\,\theta_{1},\,\ldots\theta_{n}\right.$.&lt;/li&gt;
&lt;li&gt;Sample $\theta_{1}'$ from $\theta_{1}\left|\theta_{0}',\,\theta_{2},\ldots\theta_{n}\right.$.&lt;/li&gt;
&lt;li&gt;$\vdots$&lt;/li&gt;
&lt;li&gt;Sample $\theta_{k}'$ from $\theta_{k}\left|\theta_{0}',\,\theta_{1}',\ldots,\,\theta_{k-1}',\,\theta_{k+1},\,\ldots\theta_{n}\right.$&lt;/li&gt;
&lt;/ul&gt;&lt;/ol&gt;


&lt;p align=&quot;justify&quot;&gt;However, notice that we need the conditional distributions. The advantage of Gibbs sampling is that it reduces the need for &quot;tuning&quot; as in the case for the Metropolis-Hastings algorithm. In particular, the starting point can be guessed or can be found using an optimisation algorithm. &lt;/p&gt;

&lt;h2&gt;Example - Bayesian Linear Regression&lt;/h2&gt;

&lt;p align=&quot;justify&quot;&gt;We consider a simple Bayesian Linear Regression to illustrate Gibbs sampling in practice. Suppose we have the datapoints, $\mathcal{D}=\left\{ x_{i},\,y_{i}\right\} $ for $i=1,\,2,\ldots N$ which have been generated from the model $y=\theta_{0}+\theta_{1}x$.
In other words,&lt;/p&gt; 

\begin{align}
y=\theta_{0}+\theta_{1}x+\epsilon
\end{align}


&lt;p align=&quot;justify&quot;&gt;where $\epsilon\sim\mathcal{N}\left(0.0,\,\sigma_{n}^{2}\right)$. Our aim is the find the full posterior distributions of the parameters $\theta_{0}$ and $\theta_{1}$. The joint posterior distribution is simply &lt;/p&gt;

\begin{align}
\mathcal{P}\left(\theta_{0},\,\theta_{1}\left|\mathcal{D}\right.\right)\propto\mathcal{P}\left(\mathcal{D}\left|\theta_{0},\,\theta_{1}\right.\right)\mathcal{P}\left(\theta_{0},\,\theta_{1}\right)
\end{align}


&lt;p align=&quot;justify&quot;&gt; where we assume factorisable priors, that is, $\mathcal{P}\left(\theta_{0},\,\theta_{1}\right)=\mathcal{P}\left(\theta_{0}\right)\,\mathcal{P}\left(\theta_{1}\right)$ and we consider Gaussian priors such that,&lt;/p&gt;

\begin{align}
\mathcal{P}\left(\theta_{0}\right)\sim\mathcal{N}\left(\mu_{0},\,\Sigma_{0}^{2}\right)\hspace{2cm}\mathcal{P}\left(\theta_{1}\right)\sim\mathcal{N}\left(\mu_{1},\,\Sigma_{1}^{2}\right)
\end{align}

&lt;h2&gt;Procedures&lt;/h2&gt;

&lt;p align=&quot;justify&quot;&gt; We first define the design matrices, $\mathbf{D}_{0}$, $\mathbf{D}_{1}$ and the vector $\mathbf{b}$ as follows:&lt;/p&gt;

$$
\mathbf{D}_{0}=\left[\begin{matrix}
\frac{1}{\sigma_{1}}\cr
\frac{1}{\sigma_{2}}\cr
\vdots\cr
\vdots\cr
\frac{1}{\sigma_{N}}
\end{matrix}\right]\hspace{2cm}\mathbf{D}_{1}=\left[\begin{matrix}
\frac{x_{1}}{\sigma_{1}}\cr
\frac{x_{2}}{\sigma_{2}}\cr
\vdots\cr
\vdots\cr
\frac{x_{N}}{\sigma_{N}}
\end{matrix}\right]\hspace{2cm}\mathbf{b}=\left[\begin{matrix}
\frac{y_{1}}{\sigma_{1}}\cr
\frac{y_{2}}{\sigma_{2}}\cr
\vdots\cr
\vdots\cr
\frac{y_{N}}{\sigma_{N}}
\end{matrix}\right]
$$


&lt;p align=&quot;justify&quot;&gt; As we assume $\sigma_{n}$ to be known, the likelihood can be written as &lt;/p&gt;


\begin{align}
\mathcal{P}\left(\mathcal{D}\left|\theta_{0},\,\theta_{1}\right.\right)\propto\textrm{exp}\left[-\dfrac{1}{2}\left(\mathbf{b}-\theta_{0}\mathbf{D}_{0}-\theta_{1}\mathbf{D}_{1}\right)^{\textrm{T}}\left(\mathbf{b}-\theta_{0}\mathbf{D}_{0}-\theta_{1}\mathbf{D}_{1}\right)\right]
\end{align}


&lt;p align=&quot;justify&quot;&gt; and the prior as &lt;/p&gt;

\begin{align}
\mathcal{P}\left(\theta_{0}\right)\propto\textrm{exp}\left[-\dfrac{1}{2}\left(\dfrac{\theta_{0}^{2}-2\mu_{0}\theta_{0}}{\Sigma_{0}^{2}}\right)\right]\textrm{exp}\left[-\dfrac{1}{2}\left(\dfrac{\theta_{1}^{2}-2\mu_{1}\theta_{1}}{\Sigma_{1}^{2}}\right)\right]
\end{align}


&lt;p align=&quot;justify&quot;&gt; The dependence of $\theta_{0}$ in the log-joint posterior distribution, that is, $\theta_{0}\left|\theta_{1},\,\mathcal{D}\right.$ is simply&lt;/p&gt;

$$
-\dfrac{1}{2}\left[\theta_{0}^{2}\left(\mathbf{D}_{0}^{\textrm{T}}\mathbf{D}_{0}+\dfrac{1}{\Sigma_{0}^{2}}\right)+\theta_{0}\left(2\theta_{1}\mathbf{D}_{0}^{\textrm{T}}\mathbf{D}_{1}-2\mathbf{b}^{\textrm{T}}\mathbf{D}_{0}-\dfrac{2\mu_{0}}{\Sigma_{0}^{2}}\right)\right]
$$


&lt;p align=&quot;justify&quot;&gt; This is simply a quadratic function of $\theta_{0}$. If $a=\mathbf{D}_{0}^{\textrm{T}}\mathbf{D}_{0}+\dfrac{1}{\Sigma_{0}^{2}}$
and $b=2\theta_{1}\mathbf{D}_{0}^{\textrm{T}}\mathbf{D}_{1}-2\mathbf{b}^{\textrm{T}}\mathbf{D}_{0}-\dfrac{2\mu_{0}}{\Sigma_{0}^{2}}$,
then &lt;/p&gt;

$$
\mathcal{P}\left(\theta_{0}\left|\theta_{1},\,\mathcal{D}\right.\right)\propto\textrm{exp}\left[-\dfrac{1}{2}\left(a\theta_{0}^{2}+b\theta_{0}\right)\right]
$$


&lt;p align=&quot;justify&quot;&gt; After completing the square,&lt;/p&gt;

$$
\mathcal{P}\left(\theta_{0}\left|\theta_{1},\,\mathcal{D}\right.\right)\propto\textrm{exp}\left[-\dfrac{a}{2}\left(\theta_{0}+\dfrac{b}{2a}\right)^{2}\right]
$$


&lt;p align=&quot;justify&quot;&gt; This is a Gaussian distribution with mean, $\mu$ and standard deviation, $\sigma$ given by &lt;/p&gt;

$$
\mu=-\dfrac{b}{2a}=\dfrac{-\theta_{1}\Sigma_{0}^{2}\mathbf{D}_{0}^{\textrm{T}}\mathbf{D}_{1}+\Sigma_{0}^{2}\mathbf{b}^{\textrm{T}}\mathbf{D}_{0}+\mu_{0}}{\Sigma_{0}^{2}\mathbf{D}_{0}^{\textrm{T}}\mathbf{D}_{0}+1}
$$


$$
\sigma^{2}=\dfrac{1}{a}=\dfrac{\Sigma_{0}^{2}}{\Sigma_{0}^{2}\mathbf{D}_{0}^{\textrm{T}}\mathbf{D}_{0}+1}
$$


&lt;p align=&quot;justify&quot;&gt; Similarly, it can be shown that the dependence of $\theta_{1}$ in the joint posterior distribution, that is, $\mathcal{P}\left(\theta_{1}\left|\theta_{0},\,\mathcal{D}\right.\right)$ is Gaussian with &lt;/p&gt;

$$
\mu=\dfrac{-\theta_{0}\Sigma_{1}^{2}\mathbf{D}_{1}^{\textrm{T}}\mathbf{D}_{0}+\Sigma_{0}^{2}\mathbf{b}^{\textrm{T}}\mathbf{D}_{1}+\mu_{1}}{\Sigma_{1}^{2}\mathbf{D}_{1}^{\textrm{T}}\mathbf{D}_{1}+1}
$$


$$
\sigma^{2}=\dfrac{\Sigma_{1}^{2}}{\Sigma_{1}^{2}\mathbf{D}_{1}^{\textrm{T}}\mathbf{D}_{1}+1}
$$


&lt;h2&gt;Python Code&lt;/h2&gt;

&lt;p align=&quot;justify&quot;&gt; Now we have all the mathematical tools to write the Python code. The simulated data is available on &lt;a href=&quot;https://github.com/Harry45/Self-Taught/tree/master/Gibbs_Sampling&quot;&gt;Github&lt;/a&gt;. We first define the linear function and the true parameters (for the gradient, $\theta_{1}$ and the y-intercept, $\theta_{0}$) are 2.0 and 0.5. Note that in the code below, we have used m and c for the gradient and the y-intercept. We also the specify the fraction of the chain that we will later consider as burn-in.&lt;/p&gt;



&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# True Parameters&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;yint&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Fraction considered as burn-in&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;frac&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Load the data &lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loadtxt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'data_gibbs.txt'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;     &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;];&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xmin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;);&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;xmax&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;     &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sigma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;


&lt;p align=&quot;justify&quot;&gt;The next step is to create the design matrices $\mathbf{D}_{0}$, $\mathbf{D}_{1}$ and the vector $\mathbf{b}$. We also define the hyper-parameters for the Gaussian priors, followed by defining functions to sample for $m$ and $c$ respectively. We add another function which we will then use to optimize the best-fit parameters. These parameters are then used as the starting point in the Gibbs Sampling scheme.&lt;/p&gt;


&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;c&quot;&gt;# Create Design Matrices&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Dm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sigma&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Dc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sigma&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sigma&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Define Priors (Gaussian Priors)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mu_m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu_c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;si_m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;si_c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Define Functions for Sampling&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sample_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;si_m&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mu_m&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;si_m&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sample_yint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;  &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;si_c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mu_c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;si_c&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;	
	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Define the log-likelihood for optimisation&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;loglikelihood&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Sigma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;theta0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; 
  &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;     &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;chiSquare&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LA&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Sigma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;loglike&lt;/span&gt;   &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chiSquare&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 
  &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loglike&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;# Use, for example, Powell method for optimisation&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;chi_square&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loglikelihood&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;     &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;op&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;minimize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chi_square&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;args&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sigma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;method&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;'Powell'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tol&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1E-5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;theta_op&lt;/span&gt;   &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;x&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta_op&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta_op&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p align=&quot;justify&quot;&gt;We are now ready to run the sampler. In particular, we fix the number of iterations to 200 000 and we reject the first 20 % of the chains.&lt;/p&gt;


&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;iters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;2E5&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;trace&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;gibbs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;

	&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sample_yint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
		&lt;span class=&quot;n&quot;&gt;trace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trace&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;samples&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gibbs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;samples&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;frac&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):]&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# Reject first 20 % of the chains&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;


&lt;p align=&quot;justify&quot;&gt;We finally get our nice 2D posterior distribution of the parameters. &lt;/p&gt;

&lt;dl class=&quot;wp-caption aligncenter&quot; style=&quot;max-width: 500px&quot;&gt;

&lt;dt&gt;&lt;a href=&quot;&quot;&gt;&lt;img class=&quot;&quot; src=&quot;/images/triangle_plot_gibbs.png&quot; alt=&quot;2D posterior plot of the two parameters&quot; /&gt;&lt;/a&gt;&lt;/dt&gt;

&lt;dd&gt;2D posterior plot of the two parameters&lt;/dd&gt;
&lt;/dl&gt;

&lt;/p&gt;
</description>
        <pubDate>Mon, 17 Oct 2016 16:00:00 +0400</pubDate>
        <link>http://localhost:4000/blog/2016/10/Gibbs-Sampling</link>
        <guid isPermaLink="true">http://localhost:4000/blog/2016/10/Gibbs-Sampling</guid>
        
        
        <category>Machine Learning and Statistics</category>
        
      </item>
    
      <item>
        <title>BIRO - Bayesian Inference for Radio Observations</title>
        <description>&lt;style&gt;
  .bottom-three {
     margin-bottom: 0.5cm;
  }
&lt;/style&gt;

&lt;dl class=&quot;wp-caption alignright&quot; style=&quot;max-width: 420px&quot;&gt;

&lt;dt&gt;&lt;a href=&quot;&quot;&gt;&lt;img class=&quot;&quot; src=&quot;/images/superJEDI.jpg&quot; alt=&quot;superJEDI in 2013 at Flic En Flac&quot; /&gt;&lt;/a&gt;&lt;/dt&gt;

&lt;dd&gt;superJEDI in 2013 at Flic En Flac&lt;/dd&gt;
&lt;/dl&gt;

&lt;p align=&quot;justify&quot;&gt;The superJEDI was organised in 2013, at Flic En Flac in Mauritius. I was not part of this wonderful event as I was still in my second year of my undergraduate study. However, Sheean and Suraj, who will later become my friends, were part of this amazing JEDI. The interesting fact about JEDI is that it is only in these kinds of meeting that we will come up with brilliant ideas, which can then lead to publications. For me personally, the major reason behind is the active participation of all people, being from undergraduate level to the highest position in the hierarchy.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;During one of those days, as Nadeem and Bruce were walking on the seaside, Bruce proposed the idea of having a Bayesian formalism in the context of radio interferometry. This led to the so-called BIRO (Bayesian Inference for Radio Obervation) project.&lt;/p&gt;

&lt;div style=&quot;text-align: center;&quot;&gt;
&lt;iframe src=&quot;https://player.vimeo.com/video/117391380&quot; width=&quot;640&quot; height=&quot;360&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;allowfullscreen&quot;&gt; &lt;/iframe&gt; 
&lt;/div&gt;

&lt;p class=&quot;bottom-three&quot;&gt;

&lt;p align=&quot;justify&quot;&gt;The aim of this project was to determine the scientific parameters, if possible, the systematic parameters also, using the visibility data directly. The conventional way of doing this is to first produce a radio image, from which all science will be done. This seems absurb, isn't it? Why do we have to produce an image when we have the raw data? To some extent, one might argue that the data is dominated by noise and hence it will be hard to work in the Fourier space, that is, with the visibility data. This clearly suggests that the best alternative is to have a full distribution of the parameters of interest, with a summary statistics.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Michelle, who was doing her PhD with Bruce at that time, took hold of the BIRO project. She started working on it as part of her PhD. Iniyan was also part of the BIRO project. While Michelle worked mostly on Bayesian Parameter Estimation, Iniyan's work was on Bayesian Model Selection. In a nutshell, Michelle was able to infer not only the scientific parameters but also the systematic parameters in a fully Bayesian formalism. She used MCMC (Markov Chain Monte Carlo) methods to map the full posterior distributions of the parameters. On the other hand, Iniyan used &lt;a href=&quot;http://johannesbuchner.github.io/PyMultiNest/&quot;&gt; PyMultinest&lt;/a&gt; to calculate the Bayesian Evidence (the quantity which tells us how one model is favoured over another). PyMultinest also returns the posterior distributions of the parameters. An illustration from the work done by Michelle and Iniyan is shown in the above video. Compared to &lt;a href=&quot;http://cdsads.u-strasbg.fr/abs/1974A%26AS...15..417H&quot;&gt;CLEAN&lt;/a&gt;, BIRO is much better in terms of performance.&lt;/p&gt;


&lt;p align=&quot;justify&quot;&gt;Of course, the technique is not without problems. One arguement is that we have to know the sky model first, before proceeding with Bayesian Inference. Therefore, in BIRO projects, we would normally assume a known sky model, which then leads to the second assumption that the positions of the sources are known. Moreover, nested sampling is known to have unreliable performance for higher dimensions. However, the fruitful side of this fantastic idea by Bruce has led to the following publications: &lt;a href=&quot;https://arxiv.org/abs/1501.05304&quot;&gt;BIRO&lt;/a&gt;, &lt;a href=&quot;https://arxiv.org/abs/1501.07719&quot;&gt;MontBlanc&lt;/a&gt; and &lt;a href=&quot;https://arxiv.org/abs/1610.03773&quot;&gt;Resolving the blazar CGRaBS J0809+5341&lt;/a&gt;. We are currently extending the BIRO formalism to various other topics in radio astronomy.&lt;/p&gt;

&lt;/p&gt;
</description>
        <pubDate>Thu, 13 Oct 2016 11:00:00 +0400</pubDate>
        <link>http://localhost:4000/blog/2016/10/BIRO-Bayesian-Inference-For-Radio-Observations</link>
        <guid isPermaLink="true">http://localhost:4000/blog/2016/10/BIRO-Bayesian-Inference-For-Radio-Observations</guid>
        
        
        <category>Research</category>
        
      </item>
    
      <item>
        <title>Surviving A Fast Growing Community Without Dying</title>
        <description>&lt;style&gt;
blockquote {
    display: block;
    margin-top: 1em;
    margin-bottom: 1em;
    margin-left: 100px;
    margin-right: 100px;
}
&lt;/style&gt;

&lt;blockquote&gt;
&lt;p align=&quot;justify&quot;&gt;&lt;i&gt;&quot;Emotions matter. You can tell people how to behave, but you can't tell people how to think and not everyone reacts the same way&quot;&lt;/i&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;dl class=&quot;wp-caption alignright&quot; style=&quot;max-width: 400px&quot;&gt;

&lt;dt&gt;&lt;a href=&quot;&quot;&gt;&lt;img class=&quot;&quot; src=&quot;/images/flavio.jpg&quot; alt=&quot;Flavio giving his talk at PyConZA (2016)&quot; /&gt;&lt;/a&gt;&lt;/dt&gt;

&lt;dd&gt;Flavio giving his talk at PyConZA (2016)&lt;/dd&gt;
&lt;/dl&gt;

&lt;p align=&quot;justify&quot;&gt;The &lt;a href=&quot;https://za.pycon.org/&quot;&gt;PyConZA&lt;/a&gt; was organised on the 6&lt;sup&gt;th&lt;/sup&gt; and 7&lt;sup&gt;th&lt;/sup&gt; October at the River Club in Observatory. The most impressive talk, at least for me, which had nothing to do with Python was &lt;a href=&quot;https://it.linkedin.com/in/fpercoco&quot;&gt;Flavio&lt;/a&gt;'s talk. It was easy to follow him throughout the talk and he had a real sense of humour. Most importantly, I would strongly recommend this talk (which is now available on &lt;a href=&quot;https://www.youtube.com/watch?v=bW_AEmKbB_o&quot;&gt;Youtube&lt;/a&gt;) as I believe that every young persons willing to join the industry will be well prepared, at least morally.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;He started by defining the 3 most basic terms: system, culture and flexibility which were not even clear to me what they meant until he explained them in simple terms. Flavio defines a system as being a mean of empowering humans to be amazing, a culture as the way humans do things (alternatively another answer from the audience was to define it as the rule which defines how a system works) and flexibility as the level of tolerance for variance in the system. Someone in the audience also defined flexibility as the ability to change the system and the culture! Flavio went on to explain what he really meant by the above three terms. In particular, he emphasized that tolerating variance in your community is a way to empower humans, from any culture which leads them to be simply amazing. On the other hand, community creates processes, which in turn lead to governance. Governance itself is essential to ensure growth. Governance will in principle follow the community and it is therefore important to know and understand our community.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;He further described a set of attitudes and behaviours which are relevant in a growing community. Being a good listener is a crucial factor, although we cannot make everyone happy. Being humble and objective will simplify things to a huge extent. Usually, a community will set the expectations and it is important to have clear expectations in order to be objective. It is also often a good practice to set the bar at a reasonable level. Above all, communicating the expectations is the key and it is sometimes better to over-communicate! Acknowledging our colleagues at the workplace is another important factor. The contribution of each and every person leads to excellent results.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Moreover, unlike computers, humans, from different cultural background, are subject to emotion and different cultures bring different perspectives and hence, it is important that we all strive for diversity. On the other hand, tribal thinking is certainly bad. In fact, it is crucial to build a community of doers, rather than a community of ranters! It is also important to understand that many humans could wear different hats. You could be working for Facebook but you could be holding another research position in academia as well. It happens and therefore it is important to understand others' situations. On this note, we should all be aware of Time Zone! You may be based in Germany but you have a colleague in Japan and hence, you will have to cope with the situation.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;On a conclusive note, Flavio also spoke about statistics. Statistics indicate that statistics is not good! If we give a human a number, he will do anything to make it bigger. As the community grows, the processes will evolve. However, no matter how complicated it gets, &quot;technology is social before it's technical - Gilles Deleuza.&quot; On a final note, saying thanks will always make your colleague feel better and respected. &lt;/p&gt;

</description>
        <pubDate>Mon, 10 Oct 2016 16:00:00 +0400</pubDate>
        <link>http://localhost:4000/blog/2016/10/Surviving-Growing-Community</link>
        <guid isPermaLink="true">http://localhost:4000/blog/2016/10/Surviving-Growing-Community</guid>
        
        
        <category>Workshop and Conference</category>
        
      </item>
    
      <item>
        <title>JEDI - An Alternate Route to Conventional Workshops</title>
        <description>&lt;p align=&quot;justify&quot;&gt;JEDI (Joint Exchange Development Initiative) is a programme brought forward by &lt;a href=&quot;https://cosmoaims.wordpress.com/2010/01/01/bruce-bassett/&quot;&gt;Prof Bruce Bassett&lt;/a&gt;, Dr Nadeem Oozeer and their team. The idea is straightforward. In most of the conferences, people will normally present their work and if it happens that we go to two different conferences, coincidentally, we might eventually find the same persons giving the same presentations. Therefore, instead of spending so much money on conferences, why don't we bring all academic staffs and students together for one week and work on a completely new project? &lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;So, we would normally organise it in a beautiful place (possibly in a different country, so that, some of the local students can benefit from it), work together, cook together, stay together, thus eliminating the gap between students and academic staffs. Having done so in the past few years, several projects initiated in JEDIs, have not only led to publications (see for example &lt;a href=&quot;https://arxiv.org/abs/1501.05304&quot;&gt;BIRO&lt;/a&gt;) but also, students have had the chance to continue further studies, for example, undergraduate to MSc, MSc to PhD and so forth. In short, students have been able to advance in their career. For me personally, this programme also gives the students the opportunity to be future leaders.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;My participations in JEDIs have enabled me to learn a lot. I was lucky that I got the chance to be part of it at a very young age. I had good grades for my undergraduate studies (BSc (Hons) Physics with Computing) in Mauritius but I had no idea of where to use the skills and knowledge I had gained through this degree. It was not only until I participated in one JEDI that I came to learn about Data Science, Machine Learning, Deep Learning and so forth. The transfer of scientific ideas, skills, knowledge towards solving various other non-scientific problems is simply amazing. It all came back and I could use my mathematics and coding techniques again. As Steve Jobs rightly said, &quot;You can't connect the dots looking forward; you can only connect them looking backwards. So you have to trust that the dots will somehow connect in your future.&quot;&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Now that many students have an experience of how the JEDI works, we, students work together with Prof Bruce Bassett and his team to organise various such events in different places/countries in Africa. Until now, I have participated in a few of them and I was also sometimes on the organising team.&lt;/p&gt;
</description>
        <pubDate>Sun, 09 Oct 2016 12:00:00 +0400</pubDate>
        <link>http://localhost:4000/blog/2016/10/JEDI</link>
        <guid isPermaLink="true">http://localhost:4000/blog/2016/10/JEDI</guid>
        
        
        <category>Workshop and Conference</category>
        
      </item>
    
      <item>
        <title>Gaussian Process</title>
        <description>&lt;p align=&quot;justify&quot;&gt;In the most simple term, one can think of Gaussian Process, GP as being distributions over functions. It is a supervised Machine Learning technique and was developed, in the attempt, to solve regression problems (&lt;a href=&quot;https://en.wikipedia.org/wiki/Gaussian_process&quot;&gt;Wikipedia&lt;/a&gt;). The cool thing about Gaussian Process is that we don't need a &quot;parametric model&quot; to fit the data. It learns using the kernel trick. For an introduction to these techniques, I would recommend the nice review by Prof Zoubin Ghahramani on &lt;a href=&quot;http://www.nature.com/nature/journal/v521/n7553/full/nature14541.html&quot;&gt;Probabilistic Machine Learning and Artificial Intelligence &lt;/a&gt;. Other nice books for GPs are &lt;a href=&quot;http://www.gaussianprocess.org/gpml/&quot;&gt;Gaussian Processes for Machine Learning &lt;/a&gt; by Carl Edward Rasmussen and Christopher K. I. Williams and &lt;a href=&quot;https://mitpress.mit.edu/books/machine-learning-0&quot;&gt;Machine Learning - A Probabilistic Perspective&lt;/a&gt; by Kevin Murphy. Before going into the actual explanation of what a GP is, it is important to have a brief background of how to find the marginals and conditionals of a Multivariate Nomal Distribution. See Chapter 4 from Kevin Murphy's book.&lt;/p&gt;

&lt;h2&gt;Marginals and Conditionals&lt;/h2&gt;

&lt;p align=&quot;justify&quot;&gt; Consider a 2D Gaussian Distribution whose parameters are given by &lt;/p&gt;

&lt;p&gt;\begin{align}
\boldsymbol{\mu}=\left(\begin{matrix}
\mu_{1} \cr
\mu_{2}
\end{matrix}\right)\hspace{3cm}\boldsymbol{\Sigma}=\left(\begin{matrix}
\Sigma_{11} &amp;amp; \Sigma_{12}\cr
\Sigma_{21} &amp;amp; \Sigma_{22}
\end{matrix}\right)
\end{align}&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Then, the joint distribution of $x_{1}$ and $x_{2}$, that is, $\mathcal{P}\left(x_{1},\,x_{2}\right)$ can be written as&lt;/p&gt;

&lt;p&gt;\begin{align}
\mathcal{P}\left(x_{1},\,x_{2}\right)=\dfrac{1}{\left|2\pi\boldsymbol{\Sigma}\right|^{\frac{1}{2}}}\,\textrm{exp}\left[-\dfrac{1}{2}\left(\mathbf{x}-\boldsymbol{\mu}\right)^{\textrm{T}}\boldsymbol{\Sigma}^{-1}\left(\mathbf{x}-\boldsymbol{\mu}\right)\right]
\label{eq:2d_gaussian}
\end{align}&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Using $\mathcal{P}\left(x_{1},\,x_{2}\right)=\mathcal{P}\left(x_{1}\left|x_{2}\right.\right)\mathcal{P}\left(x_{2}\right)$, it can be shown that the conditional $\mathcal{P}\left(x_{1}\left|x_{2}\right.\right)$ is also a quadratic with the mean and variance given by &lt;/p&gt;

&lt;p&gt;\begin{align}
\mu_{1\left|2\right.}=\mu_{1}+\Sigma_{12}\Sigma_{22}^{-1}\left(x_{2}-\mu_{2}\right)\hspace{3cm}\Sigma_{1\left|2\right.}=\Sigma_{11}-\Sigma_{12}\Sigma_{22}^{-1}\Sigma_{21}
\label{eq:marginals}
\end{align}&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;such that&lt;/p&gt;

&lt;p&gt;\begin{align}
\mathcal{P}\left(x_{1}\left|x_{2}\right.\right)=\dfrac{1}{\sqrt{2\pi\Sigma_{1\left|2\right.}}}\,\textrm{exp}\left[-\dfrac{1}{2}\left(\dfrac{x_{1}-\mu_{1\left|2\right.}}{\Sigma_{1\left|2\right.}}\right)^{2}\right]
 \label{eq:marginals_distribution}
\end{align}&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Intuitively, this can be understood by the fact that if we take a slice across a 2D Multivariate Normal Distribution as shown in the picture below, the resulting distribution is also a Gaussian Distribution. &lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/images/2D-Gaussian.png&quot; alt=&quot;2D Gaussian Distribution&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;h2&gt;GP for Regression&lt;/h2&gt;

&lt;p align=&quot;justify&quot;&gt;In Bayesian Parameter Inference, in which case we have a parametric model $\mathcal{M}$ and some data $\mathcal{D}$, we would want to infer the posterior distribution of the parameters, that is, $\mathcal{P}\left(\boldsymbol{\theta}\left|\mathcal{M},\,\mathcal{D}\right.\right)$. On the other hand, a GP in fact defines a prior over the functions itself, such that it can be mapped to a posterior given some data $\mathcal{D}$. In this section, we will show how we can take adavantage of the nice properties of the above to predict the likely value of a function for a given $x_{*}$. The major assumption we will make is that the testing set of data is from the same distribution as the training set of data.&lt;/p&gt;

&lt;h4&gt;&lt;b&gt;Noise-Free Case&lt;/b&gt;&lt;/h4&gt;

&lt;p align=&quot;justify&quot;&gt;Suppose we have a set of data, $\mathcal{D}=\left\{ \left(x_{i},\,f_{i}\right)\right\}$ for $i=1,2,3,\ldots N$, where $f$ is assumed to be an observable without noise. Now, given $x_{*}$, we would like to predict $f_{*}$ as well as its variance, $\Sigma_{*}$. In a sense, we effectively want the posterior distributions of $f_{*}$ given $x_{*}$, $x$ and $f$. Using Bayes' Theorem, we can write &lt;/p&gt;

&lt;p&gt;\begin{align}
\mathcal{P}\left(\mathbf{f}\left|\mathbf{y},\,\mathbf{X}\right.\right)=\dfrac{\mathcal{P}\left(\mathbf{y}\left|\mathbf{X},\,\mathbf{f}\right.\right)\mathcal{P}\left(\mathbf{f}\left|\mathbf{X}\right.\right)}{\mathcal{P}\left(\mathbf{y}\left|\mathbf{X}\right.\right)}
\label{eq:BayesTheorem}
\end{align}&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;where $\mathcal{P}\left(\mathbf{f}\left|\mathbf{y},\,\mathbf{X}\right.\right)$ is the posterior distribution of the function, $\mathcal{P}\left(\mathbf{f}\left|\mathbf{X}\right.\right)$ is the prior, $\mathcal{P}\left(\mathbf{y}\left|\mathbf{X},\,\mathbf{f}\right.\right)$ is the likelihood and $\mathcal{P}\left(\mathbf{y}\left|\mathbf{X}\right.\right)$ is the marginal likelihood which is simply given by&lt;/p&gt;

&lt;p&gt;\begin{align}
\mathcal{P}\left(\mathbf{y}\left|\mathbf{X}\right.\right)=\int\mathcal{P}\left(\mathbf{y}\left|\mathbf{X},\,\mathbf{f}\right.\right)\mathcal{P}\left(\mathbf{f}\left|\mathbf{X}\right.\right)d\mathbf{f}
\label{eq:marginal_likelihood}
\end{align}&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;Given now a new data $x_{*}$, the posterior distribution of $f_{*}$ is simply obtained by marginalisation.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{P}\left(y_{*}\left|\mathbf{y},\,\mathbf{X},\,x_{*}\right.\right)=\int\mathcal{P}\left(y_{*}\left|\mathbf{f},\,x_{*}\right.\right)\mathcal{P}\left(\mathbf{f}\left|\mathbf{y},\,\mathbf{X}\right.\right)\,d\mathbf{f}&lt;/script&gt;

&lt;p align=&quot;justify&quot;&gt;The prior on the regression function which is a Gaussian Process, GP denoted by &lt;/p&gt;

&lt;p&gt;\begin{align}
f\left(\mathbf{X}\right)\sim\textrm{GP}\left(\boldsymbol{\mu}\left(\mathbf{X}\right),\,\kappa\left(\mathbf{X},\,\mathbf{X}’\right)\right)
\label{definition_gp}
\end{align}&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;where $\boldsymbol{\mu}\left(\mathbf{X}\right)$ is the mean of the function while $\kappa\left(\mathbf{X},\,\mathbf{X}'\right)$ is the covariance matrix, which is constructed using a kernel. In particular, for this example, we will consider the squared-exponential kernel,&lt;/p&gt;

&lt;p&gt;\begin{align}
\kappa\left(x,\,x’\right)=\sigma^{2}\,\textrm{exp}\left(-\dfrac{\left(x-x’\right)^{2}}{2\ell^{2}}\right)
\label{squared_exponential}
\end{align}&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;where $\ell$ and $\sigma$ control the horizontal and vertical variations respectively. The kernel encapsulates the correlation between two datapoints. What we would ideally want is the following - if two datapoints are close to each other, that is, $x-x'\approx0$, we would expect strong correlation, while if $x-x'\rightarrow\infty$, there should be minumum correlation between $x$ and $x'$. The kernel trick allows us to easily implement this. Note that there exists various other kernel types (for more details refer to &lt;a href=&quot;http://www.gaussianprocess.org/gpml/&quot;&gt;Gaussian Processes for Machine Learning &lt;/a&gt; by Carl Edward Rasmussen and Christopher K. I. Williams)&lt;/p&gt;

&lt;p&gt;\begin{align}
\kappa\left(x,\,x’\right)=\begin{cases}
\begin{matrix}
\sigma^{2}\cr
0
\end{matrix} &amp;amp; \begin{matrix}
x-x’=0\cr
x-x’\rightarrow\infty
\end{matrix}\end{cases}
\end{align}&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;For the regression problem, the joint distribution is given by &lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;% &lt;![CDATA[
\left(\begin{matrix}
\mathbf{f}\cr
\mathbf{f}_{*}
\end{matrix}\right)\sim\left(\left(\begin{matrix}
\boldsymbol{\mu}\cr
\boldsymbol{\mu}_{*}
\end{matrix}\right),\,\left(\begin{matrix}
\mathbf{K} &amp; \mathbf{K}_{*}\cr
\mathbf{K}_{*}^{\textrm{T}} &amp; \mathbf{K}_{**}
\end{matrix}\right)\right) %]]&gt;&lt;/script&gt;

&lt;p align=&quot;justify&quot;&gt;where $\mathbf{K}_{**} = \kappa\left(\mathbf{X}_{*},\,\mathbf{X}_{*}\right)$. Using the above results given by Equations \eqref{eq:marginals}, the posterior distribution $\mathcal{P}\left(f_{*}\left|\mathbf{y},\,\mathbf{X},\,x_{*}\right.\right)$ is simply&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathcal{P}\left(\mathbf{f}\left|\mathbf{X}_{*},\,\mathbf{X},\,\mathbf{f}\right.\right)=\mathcal{N}\left(\mathbf{f}_{*}\left|\boldsymbol{\mu}_{*},\,\boldsymbol{\Sigma}_{*}\right.\right)&lt;/script&gt;

&lt;p align=&quot;justify&quot;&gt; where &lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\boldsymbol{\mu}_{*}=\boldsymbol{\mu}\left(\mathbf{X}_{*}\right)+\mathbf{K}_{*}^{\textrm{T}}\mathbf{K}^{-1}\left(\mathbf{f}-\boldsymbol{\mu}\left(\mathbf{X}\right)\right)&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\boldsymbol{\Sigma}_{*}=\mathbf{K}_{**}-\mathbf{K}_{*}^{\textrm{T}}\mathbf{K}^{-1}\mathbf{K}_{*}&lt;/script&gt;

&lt;p align=&quot;justify&quot;&gt;We would notionally assume a mean function equal to 0 and the kernel must be &lt;a href=&quot;https://en.wikipedia.org/wiki/Positive-definite_matrix&quot;&gt;positive definite&lt;/a&gt;. Hence, &lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\boldsymbol{\mu}_{*}=\mathbf{K}_{*}^{\textrm{T}}\mathbf{K}^{-1}\mathbf{f}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\boldsymbol{\Sigma}_{*}=\mathbf{K}_{**}-\mathbf{K}_{*}^{\textrm{T}}\mathbf{K}^{-1}\mathbf{K}_{*}&lt;/script&gt;

&lt;h4&gt;&lt;b&gt;Noisy Case&lt;/b&gt;&lt;/h4&gt;

&lt;p&gt;If instead, we were to observe a noisy function given by $y=f\left(x\right)+\epsilon$ where $\epsilon\sim\mathcal{N}\left(0,\,\sigma_n^2\right)$, the matrix $\mathbf{K}$ is simply given by&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\mathbf{K}_n=\mathbf{K}+\sigma_n^2\mathbf{I}&lt;/script&gt;

&lt;p align=&quot;justify&quot;&gt;assuming that the observed data is corrupted by the noise independently. Then the prediction for the new function along with its uncertainty is given by&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\boldsymbol{\mu}_{*}=\mathbf{K}_{*}^{\textrm{T}}\mathbf{K}_{n}^{-1}\mathbf{f}&lt;/script&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\boldsymbol{\Sigma}_{*}=\mathbf{K}_{**}-\mathbf{K}_{*}^{\textrm{T}}\mathbf{K}_{n}^{-1}\mathbf{K}_{*}&lt;/script&gt;

&lt;h2&gt;Learning the Kernel Parameters&lt;/h2&gt;
&lt;p align=&quot;justify&quot;&gt; The way to estimate the parameters is via maxmising the marginal likelihood, $\mathcal{P}\left(\mathbf{y}\left|\mathbf{X}\right.\right)$ which is simply a multivariate Gaussian distribution given by $\mathcal{N}\left(\mathbf{y}\left|0,\,\mathbf{K}_{n}\right.\right)$. Hence, &lt;/p&gt;

&lt;p&gt;\begin{align}
\textrm{log }\mathcal{P}\left(\mathbf{y}\left|\mathbf{X}\right.\right)=-\dfrac{1}{2}\left[\mathbf{y}^{\textrm{T}}\mathbf{K}_{n}^{-1}\mathbf{y}+\textrm{log}\left|\mathbf{K}_n \right|+N\textrm{log}\left(2\pi\right)\right]
\end{align}&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;where $N$ is the number of test data points. Essentially, the third term is does not depend on the kernel parameters and is simply an additive constant. Hence, the derivative of the marginal likelihood&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\dfrac{\partial}{\partial\theta_{j}}\textrm{log }\mathcal{P}\left(\mathbf{y}\left|\mathbf{X}\right.\right)=-\dfrac{1}{2}\left[\mathbf{y}^{\textrm{T}}\dfrac{\partial\mathbf{K}_{n}^{-1}}{\partial\theta_{j}}\mathbf{y}+\dfrac{\partial}{\partial\theta_{j}}\textrm{log}\left|\mathbf{K}_{n}\right|\right]&lt;/script&gt;

&lt;p align=&quot;justify&quot;&gt;can further be simplified using the fact that $\dfrac{\partial\mathbf{K}_{n}^{-1}}{\partial\theta_{j}}=-\mathbf{K}_{n}^{-1}\dfrac{\partial\mathbf{K}_{n}}{\partial\theta_{j}}\mathbf{K}_{n}^{-1}$ and that $ \dfrac{\partial}{\partial\theta_{j}}\textrm{log}\left|\mathbf{K}_{n}\right|=\textrm{tr}\left(\mathbf{K}_{n}^{-1}\dfrac{\partial\mathbf{K}_{n}}{\partial\theta_{j}}\right)$ such that &lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\dfrac{\partial}{\partial\theta_{j}}\textrm{log }\mathcal{P}\left(\mathbf{y}\left|\mathbf{X}\right.\right)=\dfrac{1}{2}\left[\mathbf{y}^{\textrm{T}}\mathbf{K}_{n}^{-1}\dfrac{\partial\mathbf{K}_{n}}{\partial\theta_{j}}\mathbf{K}_{n}^{-1}\mathbf{y}-\textrm{tr}\left(\mathbf{K}_{n}^{-1}\dfrac{\partial\mathbf{K}_{n}}{\partial\theta_{j}}\right)\right]&lt;/script&gt;

&lt;p align=&quot;justify&quot;&gt;Given that we now have the gradient, one could easily use an optimisation algorithm to estimate the hyper-parameters. An alternative method is to have a full Bayesian formalism for inferring the posterior distributions of the hyper-parameters.&lt;/p&gt;

&lt;h2&gt;Examples&lt;/h2&gt;
&lt;p align=&quot;justify&quot;&gt;Below, we consider two examples: noise-free and a noisy. For the following, for illustration, we assume that the kernel parameters $\sigma$ and $\ell$ are both equal to 1. We show how the Gaussian Process performs well in the noise-free and equally-spaced data as shown below. We consider a simple sinusoidal function of the form&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;f=\textrm{sin}\left(x\right)\hspace{2cm}\left[0,\,2\pi\right]&lt;/script&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/images/example_1_uniform.png&quot; alt=&quot;uniform_gp&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt; On the other hand, we generate noisy data, which are not equally-spaced. The point which we are mostly interested in is that the Gaussian Process basically demonstrates the level of confidence when we have or do not have data. As expected, we would be more confident when we have more data, and less confident when we don't have data. &lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;&lt;img src=&quot;/images/example_1_non_uniform.png&quot; alt=&quot;non_uniform_gp&quot; width=&quot;60%&quot; height=&quot;60%&quot; /&gt;&lt;/p&gt;

</description>
        <pubDate>Sat, 08 Oct 2016 16:00:00 +0400</pubDate>
        <link>http://localhost:4000/blog/2016/10/Gaussian-Process</link>
        <guid isPermaLink="true">http://localhost:4000/blog/2016/10/Gaussian-Process</guid>
        
        
        <category>Machine Learning and Statistics</category>
        
      </item>
    
      <item>
        <title>A Brief Overview of my Undergraduate Project</title>
        <description>&lt;dl class=&quot;wp-caption alignright&quot; style=&quot;max-width: 350px&quot;&gt;

&lt;dt&gt;&lt;a href=&quot;&quot;&gt;&lt;img class=&quot;&quot; src=&quot;/images/overlay_1.jpg&quot; alt=&quot;Hydra A&quot; /&gt;&lt;/a&gt;&lt;/dt&gt;

&lt;dd&gt;Hydra A&lt;/dd&gt;
&lt;/dl&gt;

&lt;p align=&quot;justify&quot;&gt; X-ray cavities are bubbles which have been formed by the central active galactic nucleus (AGN) found at the centre of galaxy clusters, groups and giant ellipticals. There is an increasing evidence, as observed from radio/x-ray overlays, that these cavities are formed by the tip of jets of the central radio galaxy and is connected back to the nucleus, in a channel-like structure. These cavities are detected in x-ray images as surface brightness depressions. Besides, most these cavities are filled with radio-emission at 1.4 GHz while, there do exist cavities, referred to as ”ghost” bubbles which are misaligned with respect to the jet and are observed at lower radio frequency.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt; The formation of X-ray cavities is a consequence of AGN feedback which is responsible for the formation of other structures such as shocks and ripples. Typically, the formation of these structures may offset cooling in galaxy clusters and might presumably be one of the solutions to the classical cooling flow issue, which was proposed by &lt;a href=&quot;https://ned.ipac.caltech.edu/level5/Fabian3/frames.html&quot;&gt;Fabian (1994)&lt;/a&gt;. &lt;/p&gt;

&lt;dl class=&quot;wp-caption alignleft&quot; style=&quot;max-width: 400px&quot;&gt;

&lt;dt&gt;&lt;a href=&quot;&quot;&gt;&lt;img class=&quot;&quot; src=&quot;/images/overlay_2.jpg&quot; alt=&quot;RBS 797 &quot; /&gt;&lt;/a&gt;&lt;/dt&gt;

&lt;dd&gt;RBS 797 &lt;/dd&gt;
&lt;/dl&gt;

&lt;p align=&quot;justify&quot;&gt; Originally, it was believed that a cooling flow must be established at the centre of cluster of galaxy as the central atmosphere being very dense and hot, the x-ray gas must lose energy via the emission of x-ray. However, after the launching of Chandra and XMM-Newton satellites in the year 1999, it was observed that relatively little gas actually cools below 2 keV. We have investigated 9 clusters of galaxies, having redshifts $0.01 &amp;lt; z &amp;lt; 0.35$, which host x-ray cavities using CIAO 4.6 and CALDB 4.5.9. These cavities are aged about $10^7$ years. The most commonly used methods for calculating cavity ages include refill timescale $\left(t_r\right)$, buoyancy timescale $\left(t_b\right)$ and sound-crossing timescale $\left(t_s\right)$. In particular, $t_r &amp;lt; t_b &amp;lt; t_s$. The enthalpy of a cavity depends on the nature of lobes and lies between $2pV$ and $4pV$ as described by &lt;a href=&quot;https://arxiv.org/abs/0709.2152&quot;&gt;McNamara and Nulsen (2007)&lt;/a&gt;.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt; The cavity power can be determined using the cavity age and enthalpy and is of the order of $10^{44}\, \textrm{ergs s}^{−1}$. In addition, the central radio source of each cluster of galaxy was studied, dealing with both strong and weak radio galaxies. Their radio luminosities at 1.4 GHz were calculated, using symbolic programming method in Matlab 2012Ra and typical value of radio luminosity $\left(\textrm{L}_{\textrm{rad}}\right)$ ranges from $0.9 − 315 \times 10^{42}\, \textrm{ergs s}^{−1}$. Using these values, together with the determined cavity power, a plot of radio luminosity against cavity power was made in the logarithmic scale, and it was found that the cavity power $\textrm{P}_{\textrm{cav}}$ varies as &lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\textrm{P}_{\textrm{cav}} = \left(5 \times 10^{38\pm1}\right)\,\textrm{L}_{\textrm{rad}}^{0.13\pm0.13}&lt;/script&gt;

&lt;dl class=&quot;wp-caption alignright&quot; style=&quot;max-width: 410px&quot;&gt;

&lt;dt&gt;&lt;a href=&quot;&quot;&gt;&lt;img class=&quot;&quot; src=&quot;/images/overlay_3.jpg&quot; alt=&quot;Abell 2052&quot; /&gt;&lt;/a&gt;&lt;/dt&gt;

&lt;dd&gt;Abell 2052&lt;/dd&gt;
&lt;/dl&gt;

&lt;p align=&quot;justify&quot;&gt;&lt;a href=&quot;https://arxiv.org/abs/astro-ph/0605323&quot;&gt;Rafferty et al. (2006)&lt;/a&gt; argued that the formation of x-ray cavities may be modelled by the mass accretion model. In this scenario, the jet is produced when a fraction of the gravitational binding energy of the material accreted is converted into outburst energy. While in another theory developed by &lt;a href=&quot;https://arxiv.org/abs/astro-ph/9810352&quot;&gt;Meier (1999)&lt;/a&gt;, it is possible for cavities to be formed via the spinning of the central rotating black hole. In this model, the spin energy is converted into jet power via a torque applied by the poloidal magnetic field strength.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;There could be different scenarios possible. For example, for Hydra A, the jet is aligned with the cavities while in RBS 797, the jet is roughly perpendicular to the orientation of the two cavities. On the other hand, Abell 2052 depicts an intricate ongoing activity at the core site.&lt;/p&gt;

&lt;p align=&quot;justify&quot;&gt;On a conclusive note, the coupling between the radio galaxy and cavities still needs to be fully exploited. Jets and cavities heat the intracluster medium, thereby inhibiting cooling flow and affects accretion and galaxy growth. In fact, the nature of cavities, more precisely, its non-thermal nature opens a new world towards the study of magnetism in these characteristic sites. &lt;/p&gt;
</description>
        <pubDate>Fri, 07 Oct 2016 10:00:00 +0400</pubDate>
        <link>http://localhost:4000/blog/2016/10/A-Brief-Overview-Of-My-Undergraduate-Project</link>
        <guid isPermaLink="true">http://localhost:4000/blog/2016/10/A-Brief-Overview-Of-My-Undergraduate-Project</guid>
        
        
        <category>Research</category>
        
      </item>
    
  </channel>
</rss>
